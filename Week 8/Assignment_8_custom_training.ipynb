{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment 8 - custom_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Custom training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LXMVuV0VhDr"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiolgWMPgpwI"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMiFcDzE7Qu3"
      },
      "source": [
        "## Fit a linear model\n",
        "\n",
        "Use the concepts you have learned so far—`Tensor`, `Variable`, and `GradientTape`—to build and train a simple model.\n",
        "\n",
        "Create a simple linear model, `f(x) = x * x * x * W2 + x * W1 + b`, which has two variables: `W2` and `W1` (weights) and `b` (bias). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFzH64Jn9PIm"
      },
      "source": [
        "### Define the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WRu7Pze7wk8"
      },
      "source": [
        "# Initialize the W2, W1 to `2.0`, `5.0`; Bias to `0.0`\n",
        "class Model(object):\n",
        "  def __init__(self):\n",
        "    self.W2 = tf.Variable(2.0)\n",
        "    self.W1 = tf.Variable(5.0)\n",
        "    self.b = tf.Variable(0.0)\n",
        "  def __call__(self, x):\n",
        "    return self.W2 * x * x * x + self.W1 * x + self.b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H11pTAZxSxK"
      },
      "source": [
        "### What will be the output of the model before training if we give x = 2.0 as input?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHS8eLmNRXrV"
      },
      "source": [
        "model = Model()\n",
        " \n",
        "model(2.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa6j_yXa-j79"
      },
      "source": [
        "### Define a loss function\n",
        "\n",
        "Use the standard L2 loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ysUFGY924U"
      },
      "source": [
        "# write code here\n",
        "def loss(predicted_y, target_y):\n",
        "  return tf.reduce_mean(tf.square(predicted_y - target_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qutT_fkl_CBc"
      },
      "source": [
        "### Obtain training data\n",
        "\n",
        "First, synthesize the training data by adding random Gaussian (Normal) noise to the inputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxPTb-kt_N5m"
      },
      "source": [
        "TRUE_W2 = 1.0\n",
        "TRUE_W1 = 0.0\n",
        "TRUE_b = 0.0\n",
        "NUM_EXAMPLES = 1000\n",
        "\n",
        "inputs  = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "noise   = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "outputs = inputs * inputs * inputs * TRUE_W2 + inputs * TRUE_W1 + TRUE_b + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-50nq-wPBsAW"
      },
      "source": [
        "Before training the model, visualize the loss value by plotting the model's predictions in red and the training data in blue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eb83LtrB4nt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(inputs, outputs, c='b')\n",
        "plt.scatter(inputs, model(inputs), c='r')\n",
        "plt.show()\n",
        "\n",
        "print('Current loss: %1.6f' % loss(model(inputs), outputs).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSDP-yeq_4jE"
      },
      "source": [
        "### Define a training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBIACgdnA55X"
      },
      "source": [
        "def train(model, inputs, outputs, learning_rate):\n",
        "  # write code here \n",
        "  with tf.GradientTape() as t:\n",
        "    current_loss = loss(model(inputs), outputs)\n",
        "  dW1, dW2, db = t.gradient(current_loss, [model.W1, model.W2, model.b])\n",
        "  model.W1.assign_sub(learning_rate * dW1)\n",
        "  model.W2.assign_sub(learning_rate * dW2)\n",
        "  model.b.assign_sub(learning_rate * db)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdfkR223D9dW"
      },
      "source": [
        "model = Model()\n",
        "\n",
        "# Run for 30 epochs\n",
        "# Use learning rate as 0.01\n",
        "W1s,W2s, bs = [], [], []\n",
        "epochs = range(31)\n",
        "for epoch in epochs:\n",
        "  W1s.append(model.W1.numpy())\n",
        "  W2s.append(model.W2.numpy())\n",
        "  bs.append(model.b.numpy())\n",
        "  current_loss = loss(model(inputs), outputs)\n",
        "\n",
        "  train(model, inputs, outputs, learning_rate=0.01)\n",
        "  print('Epoch %2d: W1=%1.2f W2=%1.2f, b=%1.2f, loss=%2.5f' %\n",
        "        (epoch, W1s[-1], W2s[-1],bs[-1], current_loss))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg8rSK7DWMiT"
      },
      "source": [
        "What is the range of loss after the 30th epoch if the learning rate was 0.001?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnz_EqCZV4UV"
      },
      "source": [
        "model = Model()\n",
        "\n",
        "# Run for 30 epochs\n",
        "# Use learning rate as 0.001\n",
        "W1s,W2s, bs = [], [], []\n",
        "epochs = range(31)\n",
        "for epoch in epochs:\n",
        "  W1s.append(model.W1.numpy())\n",
        "  W2s.append(model.W2.numpy())\n",
        "  bs.append(model.b.numpy())\n",
        "  current_loss = loss(model(inputs), outputs)\n",
        "\n",
        "  train(model, inputs, outputs, learning_rate=0.001)\n",
        "  print('Epoch %2d: W1=%1.2f W2=%1.2f, b=%1.2f, loss=%2.5f' %\n",
        "        (epoch, W1s[-1], W2s[-1],bs[-1], current_loss))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8vWm52QA89g"
      },
      "source": [
        "What will be the values of ​ z+w​ if we execute the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aYJ2nkwWTCg"
      },
      "source": [
        "x = tf.constant(2.0)\n",
        "with tf.GradientTape(persistent=True) as t:\n",
        "  t.watch(x)\n",
        "  y = x * x * x\n",
        "  z = y * y\n",
        "  w = z + 2*y + x\n",
        "dw_dx = t.gradient(w, x)\n",
        "dz_dx = t.gradient(z, x)\n",
        "dy_dx = t.gradient(y, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqEN2aQEBty2",
        "outputId": "8f2ceacf-c9b2-4a41-e775-c803af69367e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z+w"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=146.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E2lgH0bB9jv",
        "outputId": "54db2600-d685-4863-93a5-2205e7a4c32c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dw_dx"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=217.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DZwJIcICAJp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}